{"format": "layers-model", "generatedBy": "keras v2.4.0", "convertedBy": "TensorFlow.js Converter v3.3.0", "modelTopology": {"keras_version": "2.4.0", "backend": "tensorflow", "model_config": {"class_name": "Functional", "config": {"name": "model_2", "layers": [{"class_name": "InputLayer", "config": {"batch_input_shape": [null, null], "dtype": "int32", "sparse": false, "ragged": false, "name": "input_word_ids"}, "name": "input_word_ids", "inbound_nodes": []}, {"class_name": "keras_nlp>OnDeviceEmbedding", "config": {"name": "word_embeddings", "trainable": true, "dtype": "float32", "vocab_size": 30000, "embedding_width": 128, "initializer": {"class_name": "TruncatedNormal", "config": {"mean": 0.0, "stddev": 0.02, "seed": null}, "__passive_serialization__": true}, "use_one_hot": false, "scale_factor": null}, "name": "word_embeddings", "inbound_nodes": [[["input_word_ids", 0, 0, {}]]]}, {"class_name": "InputLayer", "config": {"batch_input_shape": [null, null], "dtype": "int32", "sparse": false, "ragged": false, "name": "input_type_ids"}, "name": "input_type_ids", "inbound_nodes": []}, {"class_name": "keras_nlp>PositionEmbedding", "config": {"name": "position_embedding", "trainable": true, "dtype": "float32", "max_length": 512, "initializer": {"class_name": "TruncatedNormal", "config": {"mean": 0.0, "stddev": 0.02, "seed": null}}}, "name": "position_embedding", "inbound_nodes": [[["word_embeddings", 0, 0, {}]]]}, {"class_name": "keras_nlp>OnDeviceEmbedding", "config": {"name": "type_embeddings", "trainable": true, "dtype": "float32", "vocab_size": 2, "embedding_width": 128, "initializer": {"class_name": "TruncatedNormal", "config": {"mean": 0.0, "stddev": 0.02, "seed": null}, "__passive_serialization__": true}, "use_one_hot": true, "scale_factor": null}, "name": "type_embeddings", "inbound_nodes": [[["input_type_ids", 0, 0, {}]]]}, {"class_name": "Add", "config": {"name": "add_2", "trainable": true, "dtype": "float32"}, "name": "add_2", "inbound_nodes": [[["word_embeddings", 0, 0, {}], ["position_embedding", 0, 0, {}], ["type_embeddings", 0, 0, {}]]]}, {"class_name": "LayerNormalization", "config": {"name": "embeddings/layer_norm", "trainable": true, "dtype": "float32", "axis": [2], "epsilon": 1e-12, "center": true, "scale": true, "beta_initializer": {"class_name": "Zeros", "config": {}}, "gamma_initializer": {"class_name": "Ones", "config": {}}, "beta_regularizer": null, "gamma_regularizer": null, "beta_constraint": null, "gamma_constraint": null}, "name": "embeddings/layer_norm", "inbound_nodes": [[["add_2", 0, 0, {}]]]}, {"class_name": "Dropout", "config": {"name": "dropout_5", "trainable": true, "dtype": "float32", "rate": 0.0, "noise_shape": null, "seed": null}, "name": "dropout_5", "inbound_nodes": [[["embeddings/layer_norm", 0, 0, {}]]]}, {"class_name": "EinsumDense", "config": {"name": "embedding_projection", "trainable": true, "dtype": "float32", "output_shape": [768], "equation": "...x,xy->...y", "activation": "linear", "bias_axes": "y", "kernel_initializer": {"class_name": "TruncatedNormal", "config": {"mean": 0.0, "stddev": 0.02, "seed": null}}, "bias_initializer": {"class_name": "Zeros", "config": {}}, "kernel_regularizer": null, "bias_regularizer": null, "activity_regularizer": null, "kernel_constraint": null, "bias_constraint": null}, "name": "embedding_projection", "inbound_nodes": [[["dropout_5", 0, 0, {}]]]}, {"class_name": "InputLayer", "config": {"batch_input_shape": [null, null], "dtype": "int32", "sparse": false, "ragged": false, "name": "input_mask"}, "name": "input_mask", "inbound_nodes": []}, {"class_name": "keras_nlp>SelfAttentionMask", "config": {"name": "self_attention_mask_1", "trainable": true, "dtype": "float32"}, "name": "self_attention_mask_1", "inbound_nodes": [[["embedding_projection", 0, 0, {}], ["input_mask", 0, 0, {}]]]}, {"class_name": "keras_nlp>TransformerEncoderBlock", "config": {"name": "transformer", "trainable": true, "dtype": "float32", "num_attention_heads": 12, "inner_dim": 3072, "inner_activation": "Text>gelu", "output_dropout": {"class_name": "Dropout", "config": {"name": "dropout_2", "trainable": true, "dtype": "float32", "rate": 0.0, "noise_shape": null, "seed": null}, "__passive_serialization__": true}, "attention_dropout": {"class_name": "Dropout", "config": {"name": "dropout", "trainable": true, "dtype": "float32", "rate": 0.0, "noise_shape": null, "seed": null}, "__passive_serialization__": true}, "output_range": null, "kernel_initializer": {"class_name": "TruncatedNormal", "config": {"mean": 0.0, "stddev": 0.02, "seed": null}}, "bias_initializer": {"class_name": "Zeros", "config": {}}, "kernel_regularizer": null, "bias_regularizer": null, "activity_regularizer": null, "kernel_constraint": null, "bias_constraint": null, "use_bias": true, "norm_first": false, "norm_epsilon": 1e-12, "inner_dropout": 0.0, "attention_initializer": {"class_name": "TruncatedNormal", "config": {"mean": 0.0, "stddev": 0.02, "seed": null}}}, "name": "transformer", "inbound_nodes": [[["embedding_projection", 0, 0, {}], ["self_attention_mask_1", 0, 0, {}]], [["transformer", 0, 0, {}], ["self_attention_mask_1", 0, 0, {}]], [["transformer", 1, 0, {}], ["self_attention_mask_1", 0, 0, {}]], [["transformer", 2, 0, {}], ["self_attention_mask_1", 0, 0, {}]], [["transformer", 3, 0, {}], ["self_attention_mask_1", 0, 0, {}]], [["transformer", 4, 0, {}], ["self_attention_mask_1", 0, 0, {}]], [["transformer", 5, 0, {}], ["self_attention_mask_1", 0, 0, {}]], [["transformer", 6, 0, {}], ["self_attention_mask_1", 0, 0, {}]], [["transformer", 7, 0, {}], ["self_attention_mask_1", 0, 0, {}]], [["transformer", 8, 0, {}], ["self_attention_mask_1", 0, 0, {}]], [["transformer", 9, 0, {}], ["self_attention_mask_1", 0, 0, {}]], [["transformer", 10, 0, {}], ["self_attention_mask_1", 0, 0, {}]]]}, {"class_name": "Dense", "config": {"name": "qa_outputs", "trainable": true, "dtype": "float32", "units": 2, "activation": "linear", "use_bias": true, "kernel_initializer": {"class_name": "GlorotUniform", "config": {"seed": null}}, "bias_initializer": {"class_name": "Zeros", "config": {}}, "kernel_regularizer": null, "bias_regularizer": null, "activity_regularizer": null, "kernel_constraint": null, "bias_constraint": null}, "name": "qa_outputs", "inbound_nodes": [[["transformer", 11, 0, {}]]]}], "input_layers": [["input_word_ids", 0, 0], ["input_mask", 0, 0], ["input_type_ids", 0, 0]], "output_layers": [["qa_outputs", 0, 0]]}}}, "weightsManifest": [{"paths": ["group1-shard1of11.bin", "group1-shard2of11.bin", "group1-shard3of11.bin", "group1-shard4of11.bin", "group1-shard5of11.bin", "group1-shard6of11.bin", "group1-shard7of11.bin", "group1-shard8of11.bin", "group1-shard9of11.bin", "group1-shard10of11.bin", "group1-shard11of11.bin"], "weights": [{"name": "embedding_projection/kernel", "shape": [128, 768], "dtype": "float32"}, {"name": "embedding_projection/bias", "shape": [768], "dtype": "float32"}, {"name": "embeddings/layer_norm/gamma", "shape": [128], "dtype": "float32"}, {"name": "embeddings/layer_norm/beta", "shape": [128], "dtype": "float32"}, {"name": "position_embedding/embeddings", "shape": [512, 128], "dtype": "float32"}, {"name": "qa_outputs/kernel", "shape": [768, 2], "dtype": "float32"}, {"name": "qa_outputs/bias", "shape": [2], "dtype": "float32"}, {"name": "transformer/self_attention/query/kernel", "shape": [768, 12, 64], "dtype": "float32"}, {"name": "transformer/self_attention/query/bias", "shape": [12, 64], "dtype": "float32"}, {"name": "transformer/self_attention/key/kernel", "shape": [768, 12, 64], "dtype": "float32"}, {"name": "transformer/self_attention/key/bias", "shape": [12, 64], "dtype": "float32"}, {"name": "transformer/self_attention/value/kernel", "shape": [768, 12, 64], "dtype": "float32"}, {"name": "transformer/self_attention/value/bias", "shape": [12, 64], "dtype": "float32"}, {"name": "transformer/self_attention/attention_output/kernel", "shape": [12, 64, 768], "dtype": "float32"}, {"name": "transformer/self_attention/attention_output/bias", "shape": [768], "dtype": "float32"}, {"name": "transformer/self_attention_layer_norm/gamma", "shape": [768], "dtype": "float32"}, {"name": "transformer/self_attention_layer_norm/beta", "shape": [768], "dtype": "float32"}, {"name": "transformer/intermediate/kernel", "shape": [768, 3072], "dtype": "float32"}, {"name": "transformer/intermediate/bias", "shape": [3072], "dtype": "float32"}, {"name": "transformer/output/kernel", "shape": [3072, 768], "dtype": "float32"}, {"name": "transformer/output/bias", "shape": [768], "dtype": "float32"}, {"name": "transformer/output_layer_norm/gamma", "shape": [768], "dtype": "float32"}, {"name": "transformer/output_layer_norm/beta", "shape": [768], "dtype": "float32"}, {"name": "type_embeddings/embeddings", "shape": [2, 128], "dtype": "float32"}, {"name": "word_embeddings/embeddings", "shape": [30000, 128], "dtype": "float32"}]}]}